{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Perplexity\n",
        "\n",
        "In our seminars on n-gram language modelling we used models to assign probabilities to sentences that weren't in our training set. As I noted at the time this value (the negative log likelihood of the sentence) was length dependent and so needed to be normalised for length. The length-normalised measure that we use is called Perplexity.\n",
        "\n",
        "Before we get to that, it is important to introduce you to the measure of cross entropy. In a previous lecture you encountered entropy â€“ the average surprisal of a known distribution P when presented with random draws from P.\n",
        "\n",
        "H(P) = -Sum_i=0_N p(x_i) log2 p(x_i)\n",
        "\n",
        "The related measure of cross entropy is the average surprisal of a different distribution Q when presented with random draws from P:\n",
        "\n",
        "H(P,Q) = -Sum_i=0_N p(x_i) log2 q(x_i)\n",
        "\n",
        "For a given language sample this reduces to the average log probability of the observed words (or characters). Thus if we take the negative log probability that our model assigned to our sequence and divide it by the length of the sequence, then we have a measure of cross entropy.\n",
        "\n",
        "To calculate the perplexity we simply raise the number 2 to this cross entropy.\n",
        "\n",
        "2^\\[H(P,Q)/N\\]\n",
        "\n",
        "There are two different ways that we can arrive at this value, and because you will encounter both measures in the literature, I will include the code for both below, using the example from Jurafsky and Martin's textbook.\n",
        "\n"
      ],
      "metadata": {
        "id": "SwKukaTPOCpH"
      },
      "id": "SwKukaTPOCpH"
    },
    {
      "cell_type": "markdown",
      "id": "8123fafe",
      "metadata": {
        "id": "8123fafe"
      },
      "source": [
        "## Calculating Perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate perplexity via cross entropy"
      ],
      "metadata": {
        "id": "zw8O-rMsR2y9"
      },
      "id": "zw8O-rMsR2y9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78b3ee9",
      "metadata": {
        "id": "f78b3ee9"
      },
      "outputs": [],
      "source": [
        "# Set probabilities as states in chapter\n",
        "from collections import defaultdict\n",
        "unigrams = defaultdict(int)\n",
        "unigrams[\"red\"] = 8\n",
        "unigrams[\"blue\"] = 1\n",
        "unigrams[\"green\"] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a471e6a1",
      "metadata": {
        "id": "a471e6a1",
        "outputId": "6117c041-015b-4845-b534-f6bba0670ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.609640474436811"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Calculate the log probability of their test sentence given the probabilities\n",
        "import math\n",
        "sentence = [\"red\",\"red\",\"red\",\"red\",\"blue\"]\n",
        "log_prob=0.0\n",
        "# Iterate through the sentence from 0 to the length of the sentence minus 1 (because working with bigrams)\n",
        "for i in range(len(sentence)):\n",
        "  log_prob += -math.log(unigrams[sentence[i]]/10, 2)\n",
        "log_prob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pow(2,log_prob/5)"
      ],
      "metadata": {
        "id": "QpjCwiMaRZt9",
        "outputId": "8f13f3d6-5f91-466e-e84c-6209902ba848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QpjCwiMaRZt9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8946457081379975"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate directly from probabilities"
      ],
      "metadata": {
        "id": "qIXiGC3qRo62"
      },
      "id": "qIXiGC3qRo62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350035a4",
      "metadata": {
        "id": "350035a4",
        "outputId": "1f513af7-5d70-4574-f698-f962c848747c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04096000000000002"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the probability of the test sentence given the probabilities\n",
        "import math\n",
        "sentence = [\"red\",\"red\",\"red\",\"red\",\"blue\"]\n",
        "prob=1.0\n",
        "# Iterate through the sentence from 0 to the length of the sentence minus 1 (because working with bigrams)\n",
        "for i in range(len(sentence)):\n",
        "  prob *= unigrams[sentence[i]]/10\n",
        "prob\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49d95afe",
      "metadata": {
        "id": "49d95afe",
        "outputId": "6934d803-e262-4157-bc48-2f155169ccf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-4.609640474436811"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math.log(prob,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1bdb99",
      "metadata": {
        "id": "6f1bdb99"
      },
      "outputs": [],
      "source": [
        "pow(prob,-1/len(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6184b7",
      "metadata": {
        "id": "3a6184b7",
        "outputId": "a426a870-0dbe-4b2d-9e7a-83932219c5df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.8921152934511918"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pow(2,0.92)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}