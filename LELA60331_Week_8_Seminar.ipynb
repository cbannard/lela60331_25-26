{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3e70908"
      },
      "source": [
        "# Week 8 Seminar: From Binary Logistic Regression to Multiclass Multilayer Neural Networks - part 1\n",
        "\n"
      ],
      "id": "d3e70908"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This week we are going to look at multiclass classification and start looking at multilayer networks"
      ],
      "metadata": {
        "id": "JrWfN1IG43i5"
      },
      "id": "JrWfN1IG43i5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiclass classification problems\n",
        "\n",
        "While logistic regression is great for binary classification tasks, many classification problems have more than two possible outcomes.  We can simulate such a situation as follows. I have just generalised sentiment analysis to a three class problem - negative, neutral and positive.\n",
        "\n"
      ],
      "metadata": {
        "id": "58xkbBkUzkVW"
      },
      "id": "58xkbBkUzkVW"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "## Create simulated data\n",
        "np.random.seed(10)\n",
        "w1_center = (1, 3)\n",
        "w2_center = (3, 1)\n",
        "w3_center = (1, 1)\n",
        "w4_center = (3, 3)\n",
        "\n",
        "x=np.concatenate((np.random.normal(loc=w1_center,size=(20,2)),np.random.normal(loc=w2_center,size=(20,2)),np.random.normal(loc=w3_center,size=(10,2)),np.random.normal(loc=w4_center,size=(10,2))))\n",
        "labs=np.repeat([0,1,2],[20,20,20],axis=0)\n",
        "y=np.repeat(np.diag((1,1,1)),[20,20,20],axis=0)\n",
        "x=x.T\n",
        "y=y.T"
      ],
      "metadata": {
        "id": "k-yx9h_40DIl"
      },
      "execution_count": 1,
      "outputs": [],
      "id": "k-yx9h_40DIl"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x[0][labs==0], x[1][labs==0], marker='*', s=100)\n",
        "plt.scatter(x[0][labs==1], x[1][labs==1], marker='o', s=100)\n",
        "plt.scatter(x[0][labs==2], x[1][labs==2], marker='x', s=100)\n",
        "plt.xlabel(\"log count of negative words\")\n",
        "plt.ylabel(\"log count of positive words\")\n",
        "plt.xlim((0,5))\n",
        "plt.ylim((0,5))\n"
      ],
      "metadata": {
        "id": "I3japJAV50NE"
      },
      "execution_count": null,
      "outputs": [],
      "id": "I3japJAV50NE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Softmax\n",
        "In such circumstances we need to use multinomial logistic (aka softmax) regression.\n",
        "\n",
        "In logistic regression we take the dot product between our feature vector for each data point and our weight vector. We then add the bias to give us a single z value which we feed through the sigmoid function. We can have only one z values because there are only two outcomes and the following relationship holds:\n",
        "p(y=0|x) = 1-p(y-1)\n",
        "\n",
        "In multinomial regression we instead have a z value for each of our possible outcomes. We can use these collectively to calculate probabilties for each of our possible outcomes. For example if we had three possible outcomes, 0, 1 or 2 then we would calculate their probabilities as follows:\n",
        "\n",
        "$p(y=0|x) = \\frac{exp(z_{0})}{\\sum_{i,N} exp(z_i)}$ \\\\\n",
        "$p(y=1|x) = \\frac{exp(z_{1})}{\\sum_{i,N} exp(z_i)}$ \\\\\n",
        "$p(y=2|x) = \\frac{exp(z_{2})}{\\sum_{i,N} exp(z_i)}$ \\\\\n"
      ],
      "metadata": {
        "id": "v6QacNfX8TPj"
      },
      "id": "v6QacNfX8TPj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1: A fitted model might return the following weights. In Python calculate the probabilites of each of the output classes for the following inputs. \\\\\n",
        "\n",
        "\n",
        "a) x[0] (positive words) = 10, x[1] (negative words) = 3 \\\\\n",
        "a) x[0] (positive words) = 3, x[1] (negative words) = 3 \\\\\n",
        "a) x[0] (positive words) = 1, x[1] (negative words) = 6 \\\\\n"
      ],
      "metadata": {
        "id": "gF0M7lm6k3O-"
      },
      "id": "gF0M7lm6k3O-"
    },
    {
      "cell_type": "code",
      "source": [
        "bias_negative=-0.82031125\n",
        "bias_positive=-0.451126\n",
        "bias_neutral = 1.27143725\n",
        "\n",
        "weights_negative = np.array([-0.69900716, 1.81182487])\n",
        "weights_positive = np.array([1.7979912 , -0.74611263])\n",
        "weights_neutral = np.array([0.80449184, -0.07135976])"
      ],
      "metadata": {
        "id": "ckqrbHUIHlON"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ckqrbHUIHlON"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: for convenience you can print a float with scientific notation with the  function np.format_float_positional, as in the following:"
      ],
      "metadata": {
        "id": "6WD2NE3nOYX4"
      },
      "id": "6WD2NE3nOYX4"
    },
    {
      "cell_type": "code",
      "source": [
        "x=1/783618\n",
        "x"
      ],
      "metadata": {
        "id": "bWU6LISqOd0t"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bWU6LISqOd0t"
    },
    {
      "cell_type": "code",
      "source": [
        "np.format_float_positional(x)"
      ],
      "metadata": {
        "id": "-A8mqC3fOiEO"
      },
      "execution_count": null,
      "outputs": [],
      "id": "-A8mqC3fOiEO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Representing multinomial logistic regression problems\n",
        "\n",
        "In multinomial logistic regression we have multiple outcome classes. In place of the single 0 or 1 that we used as outcome in binary logistic regression, we represent the outcome using a vector of 0s and 1, with each position in the vector corresponding to one of the output classes.\n",
        "\n",
        "positive = [1,0,0] \\\n",
        "negative = [0,1,0] \\\n",
        "neutral = [0,0,1]\n",
        "\n",
        "This is how the y variable looks in our simulated data:"
      ],
      "metadata": {
        "id": "BG8JpQ-yPbE7"
      },
      "id": "BG8JpQ-yPbE7"
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "Xft3loAtPYEY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Xft3loAtPYEY"
    },
    {
      "cell_type": "code",
      "source": [
        "y.T[1:20]"
      ],
      "metadata": {
        "id": "hcSULKmmQeF9"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hcSULKmmQeF9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exclusive OR problem\n",
        "\n",
        "Problem 2: Create the data for the AND, OR, and XOR functions. Fit a logistic regression to these problem using the code you have developed in previous problems and then inspect the output. What do you see?"
      ],
      "metadata": {
        "id": "FdW7tjtNxhRy"
      },
      "id": "FdW7tjtNxhRy"
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([])\n",
        "y=np.array([])"
      ],
      "metadata": {
        "id": "bEBOVkO-y9x9"
      },
      "id": "bEBOVkO-y9x9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your first multilayer network\n",
        "\n",
        "Problem 3: Enter the weights from the example multilayer network from the lecture and demonstrate that it can solve the XOR problem\n",
        "Remember that you have two sets of weights - those from layer 0 to layer 1 and those from layer 1 to layer 2 - and that the former is a matrix not a vector.\n"
      ],
      "metadata": {
        "id": "fCH_0E_xx2Uk"
      },
      "id": "fCH_0E_xx2Uk"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}